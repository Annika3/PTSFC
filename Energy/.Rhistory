ret2 = compute_return(Adj.Close, h = 2),
ret3 = compute_return(Adj.Close, h = 3),
ret4 = compute_return(Adj.Close, h = 4),
ret5 = compute_return(Adj.Close, h = 5))
dat_returns <- dat_returns %>% filter(format(Datum, "%Y") != "2020")
# Lags für jeden Horizont erstellen + Train/Val/Test ---------------------------------------
dax_r1 <- dat_returns %>% select("Datum", "ret1")
dax_r2 <- dat_returns %>% select("Datum", "ret2")
dax_r3 <- dat_returns %>% select("Datum", "ret3")
dax_r4 <- dat_returns %>% select("Datum", "ret4")
dax_r5 <- dat_returns %>% select("Datum", "ret5")
n_lags = 10
for (i in 1:n_lags) {
lag_name = paste0('lag_', i)
dax_r1[[lag_name]] = lag(dax_r1$ret1, n = i)
}
for (i in 1:n_lags) {
lag_name = paste0('lag_', i)
dax_r2[[lag_name]] = lag(dax_r2$ret2, n = i)
}
for (i in 1:n_lags) {
lag_name = paste0('lag_', i)
dax_r3[[lag_name]] = lag(dax_r3$ret3, n = i)
}
for (i in 1:n_lags) {
lag_name = paste0('lag_', i)
dax_r4[[lag_name]] = lag(dax_r4$ret4, n = i)
}
for (i in 1:n_lags) {
lag_name = paste0('lag_', i)
dax_r5[[lag_name]] = lag(dax_r5$ret5, n = i)
}
#Unterteilung in Train, Validation und Testset
dax_r5 <- na.omit(dax_r5)
n <- nrow(dax_r5)
dax_r1 <- tail(dax_r1, n)
dax_r2 <- tail(dax_r2, n)
dax_r3 <- tail(dax_r3, n)
dax_r4 <- tail(dax_r4, n)
n_train <- floor(0.7 * n)
n_val <- floor(0.1 * n) + n_train
dax_r1_train <- dax_r1[1:n_train, ]
dax_r1_val <- dax_r1[(n_train + 1):n_val, ]
dax_r1_test <- dax_r1[(n_val + 1):n, ]
dax_r2_train <- dax_r2[1:n_train, ]
dax_r2_val <- dax_r2[(n_train + 1):n_val, ]
dax_r2_test <- dax_r2[(n_val + 1):n, ]
dax_r3_train <- dax_r3[1:n_train, ]
dax_r3_val <- dax_r3[(n_train + 1):n_val, ]
dax_r3_test <- dax_r3[(n_val + 1):n, ]
dax_r4_train <- dax_r4[1:n_train, ]
dax_r4_val <- dax_r4[(n_train + 1):n_val, ]
dax_r4_test <- dax_r4[(n_val + 1):n, ]
dax_r5_train <- dax_r5[1:n_train, ]
dax_r5_val <- dax_r5[(n_train + 1):n_val, ]
dax_r5_test <- dax_r5[(n_val + 1):n, ]
# Modelle schätzen --------------------------------------------------------
method_dax_quantile_1 <- function (train_data, tau_level){
model <- rq(train_data[,2] ~ lag_1   , data = train_data, tau = tau_level)
return (model)
}
method_dax_quantile_2 <- function (train_data, tau_level){
model <- rq(train_data[,2] ~ lag_1   , data = train_data, tau = tau_level)
return (model)
}
method_dax_quantile_3 <- function (train_data, tau_level){
model <- rq(train_data[,2] ~ lag_1   , data = train_data, tau = tau_level)
return (model)
}
method_dax_quantile_4 <- function (train_data, tau_level){
model <- rq(train_data[,2] ~ lag_1 , data = train_data, tau = tau_level)
return (model)
}
method_dax_quantile_5 <- function (train_data, tau_level){
model <- rq(train_data[,2] ~ lag_1 , data = train_data, tau = tau_level)
return (model)
}
dax_r1_list <- list(
"0.025" = method_dax_quantile_1(dax_r1_train, 0.025),
"0.25" = method_dax_quantile_1(dax_r1_train, 0.25),
"0.5" = method_dax_quantile_1(dax_r1_train, 0.5),
"0.75" = method_dax_quantile_1(dax_r1_train, 0.75),
"0.975" = method_dax_quantile_1(dax_r1_train, 0.975)
)
dax_r2_list <- list(
"0.025" = method_dax_quantile_2(dax_r2_train, 0.025),
"0.25" = method_dax_quantile_2(dax_r2_train, 0.25),
"0.5" = method_dax_quantile_2(dax_r2_train, 0.5),
"0.75" = method_dax_quantile_2(dax_r2_train, 0.75),
"0.975" = method_dax_quantile_2(dax_r2_train, 0.975)
)
dax_r3_list <- list(
"0.025" = method_dax_quantile_3(dax_r3_train, 0.025),
"0.25" = method_dax_quantile_3(dax_r3_train, 0.25),
"0.5" = method_dax_quantile_3(dax_r3_train, 0.5),
"0.75" = method_dax_quantile_3(dax_r3_train, 0.75),
"0.975" = method_dax_quantile_3(dax_r3_train, 0.975)
)
dax_r4_list <- list(
"0.025" = method_dax_quantile_4(dax_r4_train, 0.025),
"0.25" = method_dax_quantile_4(dax_r4_train, 0.25),
"0.5" = method_dax_quantile_4(dax_r4_train, 0.5),
"0.75" = method_dax_quantile_4(dax_r4_train, 0.75),
"0.975" = method_dax_quantile_4(dax_r4_train, 0.975)
)
dax_r5_list <- list(
"0.025" = method_dax_quantile_5(dax_r5_train, 0.025),
"0.25" = method_dax_quantile_5(dax_r5_train, 0.25),
"0.5" = method_dax_quantile_5(dax_r5_train, 0.5),
"0.75" = method_dax_quantile_5(dax_r5_train, 0.75),
"0.975" = method_dax_quantile_5(dax_r5_train, 0.975)
)
# Forecasts generieren ----------------------------------------------------
dax_r1_quantreg_forecasts <- function (day, data){
datums_index <- which(data$Datum == day)
day_r1 <- datums_index +1
new_data <- data[day_r1,]
pred_ret <- rep(NA, times=5)
for (i in tau){
string_tau <- as.character(i)
model <- dax_r1_list[[string_tau]]
point <- predict(model, new_data)
index <- match(i, tau)
pred_ret[index] <- point
}
return (pred_ret)
}
dax_r2_quantreg_forecasts <- function (day, data){
datums_index <- which(data$Datum == day)
day_r2 <- datums_index +2
new_data <- data[day_r2,]
pred_ret <- matrix(nrow = 2, ncol = 5)
for(j in 1:2){
for(i in tau){
string_tau <- as.character(i)
model <- dax_r2_list[[string_tau]]
point <- predict(model, new_data)
index <- match(i, tau)
pred_ret[j, index] <- point
}
new_data$lag_5 <- new_data$lag_4
new_data$lag_4 <- new_data$lag_3
new_data$lag_3 <- new_data$lag_2
new_data$lag_2 <- new_data$lag_1
new_data$lag_1 <- pred_ret[j, 3]
}
return (pred_ret[2, ])
}
dax_r3_quantreg_forecasts <- function (day, data){
datums_index <- which(data$Datum == day)
day_r3 <- datums_index +3
new_data <- data[day_r3,]
pred_ret <- matrix(nrow = 3, ncol = 5)
for(j in 1:3){
for(i in tau){
string_tau <- as.character(i)
model <- dax_r3_list[[string_tau]]
point <- predict(model, new_data)
index <- match(i, tau)
pred_ret[j, index] <- point
}
new_data$lag_5 <- new_data$lag_4
new_data$lag_4 <- new_data$lag_3
new_data$lag_3 <- new_data$lag_2
new_data$lag_2 <- new_data$lag_1
new_data$lag_1 <- pred_ret[j, 3]
}
return (pred_ret[3, ])
}
dax_r4_quantreg_forecasts <- function (day, data){
datums_index <- which(data$Datum == day)
day_r4 <- datums_index +4
new_data <- data[day_r4,]
pred_ret <- matrix(nrow = 4, ncol = 5)
for(j in 1:4){
for(i in tau){
string_tau <- as.character(i)
model <- dax_r4_list[[string_tau]]
point <- predict(model, new_data)
index <- match(i, tau)
pred_ret[j, index] <- point
}
new_data$lag_5 <- new_data$lag_4
new_data$lag_4 <- new_data$lag_3
new_data$lag_3 <- new_data$lag_2
new_data$lag_2 <- new_data$lag_1
new_data$lag_1 <- pred_ret[j, 3]
}
return (pred_ret[4, ])
}
dax_r5_quantreg_forecasts <- function (day, data){
datums_index <- which(data$Datum == day)
day_r5 <- datums_index +5
new_data <- data[day_r5,]
pred_ret <- matrix(nrow = 5, ncol = 5)
for(j in 1:5){
for(i in tau){
string_tau <- as.character(i)
model <- dax_r5_list[[string_tau]]
point <- predict(model, new_data)
index <- match(i, tau)
pred_ret[j, index] <- point
}
new_data$lag_5 <- new_data$lag_4
new_data$lag_4 <- new_data$lag_3
new_data$lag_3 <- new_data$lag_2
new_data$lag_2 <- new_data$lag_1
new_data$lag_1 <- pred_ret[j, 3]
}
return (pred_ret[5, ])
}
# Evaluation + Forecasts generieren  -----------------------------------------
qr_evaluation_matrix <- dax_r1_val
qr_evaluation_matrix$QS <- NA
for(i in 1: (nrow(dax_r1_val) - 5)) {
print (i/ nrow(dax_r1_val)) # Fortschrittsanzeige
datum <- dax_r1_val$Datum[i]
for_r1 <- dax_r1_quantreg_forecasts (day = datum, data = dax_r1_val)
for_r2 <- dax_r2_quantreg_forecasts (day = datum, data = dax_r2_val)
for_r3 <- dax_r3_quantreg_forecasts (day = datum, data = dax_r3_val)
for_r4 <- dax_r4_quantreg_forecasts (day = datum, data = dax_r4_val)
for_r5 <- dax_r5_quantreg_forecasts (day = datum, data = dax_r5_val)
forecasts <- rbind(for_r1, for_r2, for_r3, for_r4, for_r5)
colnames(forecasts) <- c("q0.025", "q0.25", "q0.5", "q0.75", "q0.975")
qs_score <- evaluation(datum, data=dat_returns, forecasts=forecasts)
print(qs_score)
qr_evaluation_matrix$QS[i] <- qs_score
}
val <- qr_evaluation_matrix %>% filter(QS > 1)
tail(qr_evaluation_matrix)
(mean(qr_evaluation_matrix$QS, na.rm = TRUE))
source("C:/Users/monam/PTSFC - Data und Programme/R - Data/DAX/Quantil Regression.R")
library(dplyr)
library(tidyr)
library(quantreg)
setwd ("C:\\Users\\monam\\PTSFC - Data und Programme\\R - Data\\Energy")
source("Energy_Code\\Energy_methods.R")
source("Energy_Code\\Evaluation.R")
load("all_data.Rdata")
tau <-c(.025, .25, .5, .75, .975)
hist(all_data$GWh)
library(dplyr)
library(tidyr)
library(quantreg)
setwd ("C:\\Users\\monam\\PTSFC - Data und Programme\\R - Data\\Energy")
source("Energy_Code\\Energy_methods.R")
source("Energy_Code\\Evaluation.R")
load("all_data.Rdata")
tau <-c(.025, .25, .5, .75, .975)
#Unterteilung in Test & Train
set.seed(123)
unique_dates <- unique(all_data$Datum)
num_train_val_dates <- round(length(unique_dates) * 0.7)
train_val_dates <- sample(unique_dates, num_train_val_dates)
train_val_data <- all_data[all_data$Datum %in% train_val_dates, ]
test_data <- all_data[!all_data$Datum %in% train_val_dates, ]
#Unterteilung train und validate
unique_train_dates <- unique(train_val_data$Datum)
num_train_dates <- round(length(unique_train_dates) * 0.8)
train_dates <- sample(unique_train_dates, num_train_dates)
train_data <- train_val_data[train_val_data$Datum %in% train_dates, ]
val_data <- train_val_data[!train_val_data$Datum %in% train_dates, ]
# Modelle schätzen ---------------------------------------------------------
method_seasonal_quantile <- function (train_data, tau_level){
model <- rq(GWh ~ Anfang + month + holiday + day, data = train_data, tau = tau_level)
return (model)
}
seasonal_model_list <- list(
"0.025" = method_seasonal_quantile(train_data, 0.025),
"0.25" = method_seasonal_quantile(train_data, 0.25),
"0.5" = method_seasonal_quantile(train_data, 0.5),
"0.75" = method_seasonal_quantile(train_data, 0.75),
"0.975" = method_seasonal_quantile(train_data, 0.975)
)
seasonal_quantreg_forecasts <- function (d, data){
month <- format(d, "%B")
year <- format(d, "%Y")
day <- format(d, "%A")
variableday <- paste0("day", day)
variablemonth <- paste0("month", month)
pred_seasonal <- matrix(0, nrow = 3, ncol = 5)
rownames(pred_seasonal) <- c("12:00", "16:00", "20:00")
colnames(pred_seasonal) <- c("0.025", "0.25", "0.5", "0.75", "0.975")
for (i in tau){
string_tau <- as.character(i)
model <- seasonal_model_list[[string_tau]]
data_12 <- data %>% dplyr::filter(Datum == as.Date(d) & format(Anfang, format = "%H:%M") == "12:00")
data_16 <- data %>% dplyr::filter(Datum == as.Date(d) & format(Anfang, format = "%H:%M") == "16:00")
data_20 <- data %>% dplyr::filter(Datum == as.Date(d) & format(Anfang, format = "%H:%M") == "20:00")
point_12 <- predict(model, data_12)
point_16 <- predict(model, data_16)
point_20 <- predict(model, data_20)
pred_seasonal["12:00", string_tau] <- point_12
pred_seasonal["16:00", string_tau] <- point_16
pred_seasonal["20:00", string_tau] <- point_20
}
return (pred_seasonal)
}
# Validation Testing ------------------------------------------------------
test_oneday <- test_data %>% filter(Anfang == "00:00") #Subset mit jeweils nur einer Zeile pro Tag (damit jedes Test - Datum nur einmal vorkommt)
test_oneday <- test_oneday %>% filter(holiday == "FALSE") #Feiertage entfernen
validation_matrix_quantreg.df <- data.frame(matrix(ncol = 9, nrow = 0))
for (i in 1:nrow(test_oneday)){
print(i/nrow(test_oneday))
pred_quantreg <- seasonal_quantreg_forecasts(as.Date(test_oneday$Datum[i]), test_data)
evaluation_quantreg <- method_evaluation(as.Date(test_oneday$Datum[i]), test_data, pred_quantreg)
test_oneday$QS[i] <- evaluation_quantreg[1]
print(evaluation_quantreg[1])
test_oneday$BE[i] <- evaluation_quantreg[2]
print(evaluation_quantreg[2])
}
colnames(validation_matrix_quantreg.df) <- c("Datum", "2.5%", "25%", "50%", "75%", "97.5%", "actual", "Quantile Score", "Bias Error")
validation_matrix_quantreg.df$Datum <- as.Date(validation_matrix_quantreg.df$Datum) #Datumsspalte in richtiges Format bringen
(mean_qs_seasonal_quantreg <- mean(test_oneday$QS, na.rm = TRUE))
(mean_be_seasonal_quantreg <- mean(test_oneday$BE, na.rm = TRUE))
val_oneday <- val_data %>% filter(Anfang == "00:00") #Subset mit jeweils nur einer Zeile pro Tag (damit jedes val - Datum nur einmal vorkommt)
val_oneday <- val_oneday %>% filter(holiday == "FALSE") #Feiertage entfernen
validation_matrix_quantreg.df <- data.frame(matrix(ncol = 9, nrow = 0))
for (i in 1:nrow(val_oneday)){
print(i/nrow(val_oneday))
pred_quantreg <- seasonal_quantreg_forecasts(as.Date(val_oneday$Datum[i]), val_data)
evaluation_quantreg <- method_evaluation(as.Date(val_oneday$Datum[i]), val_data, pred_quantreg)
val_oneday$QS[i] <- evaluation_quantreg[1]
print(evaluation_quantreg[1])
val_oneday$BE[i] <- evaluation_quantreg[2]
print(evaluation_quantreg[2])
}
colnames(validation_matrix_quantreg.df) <- c("Datum", "2.5%", "25%", "50%", "75%", "97.5%", "actual", "Quantile Score", "Bias Error")
validation_matrix_quantreg.df$Datum <- as.Date(validation_matrix_quantreg.df$Datum) #Datumsspalte in richtiges Format bringen
(mean_qs_seasonal_quantreg <- mean(val_oneday$QS, na.rm = TRUE))
(mean_be_seasonal_quantreg <- mean(val_oneday$BE, na.rm = TRUE))
library(dplyr)
library(lubridate)
library(rugarch)
library(zoo)
library(tseries)
#setwd("C:\\Users\\monam\\PTSFC - Data und Programme\\R - Data\\DAX")
#source("dax_procs.R")
#source("Evaluation.R")
tau <- c(.025, .25, .5, .75, .975) # quantile levels
dax_data = get.hist.quote(instrument="^GDAXI", start="2010-01-01",
end="2024-02-14", quote="Adjusted",
origin="1970-01-01", provider="yahoo",
compression="d", retclass="zoo")
dax_data_filled <- na.locf(dax_data)
dax_data.df <- fortify.zoo(dax_data_filled)
dax_data.df <- rename(dax_data.df, "Datum" = "Index")
dax_data.df <- rename(dax_data.df, "Adj.Close" = "Adjusted")
dat_returns <- dax_data.df %>%
mutate(ret1 = compute_return(Adj.Close, h = 1),
ret2 = compute_return(Adj.Close, h = 2),
ret3 = compute_return(Adj.Close, h = 3),
ret4 = compute_return(Adj.Close, h = 4),
ret5 = compute_return(Adj.Close, h = 5))
dat_returns <- dat_returns[6:nrow(dat_returns), ]
dat_returns <- dat_returns %>% filter(format(Datum, "%Y") != "2020")
# Box.test((dat_returns$ret1)^2, type =c ("Ljung-Box"))
n <- nrow(dat_returns)
n_train <- floor(0.7 * n)
n_val <- floor(0.1 * n) + n_train
garch_train_data <- dat_returns[1:n_train, ]
garch_val_data <- dat_returns[(n_train + 1):n_val, ]
garch_test_data <- dat_returns[(n_val + 1):n, ]
# Modelle aufstellen ------------------------------------------------------
garch_spec_h1 <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(1,0)),
distribution.model = "norm" )
garch_fit_h1 <- ugarchfit (data = ts(garch_train_data$ret1), spec = garch_spec_h1)
print(garch_fit_h1)
garch_spec_h2 <- ugarchspec(variance.model = list(model = "sGARCH",  garchOrder = c(2, 1)),
mean.model = list(armaOrder = c(4,2)),
distribution.model = "norm" )
garch_fit_h2 <- ugarchfit (data = ts(garch_train_data$ret2), spec = garch_spec_h2)
garch_spec_h3 <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(2, 1)),
mean.model = list(armaOrder = c(4,1)),
distribution.model = "norm" )
garch_fit_h3 <- ugarchfit (data = ts(garch_train_data$ret3), spec = garch_spec_h3)
garch_spec_h4 <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(5,3)),
distribution.model = "norm" )
garch_fit_h4 <- ugarchfit (data = ts(garch_train_data$ret4), spec = garch_spec_h4)
garch_spec_h5 <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(6,3)),
distribution.model = "norm" )
garch_fit_h5 <- ugarchfit (data = ts(garch_train_data$ret5), spec = garch_spec_h5)
garch_forecasts_bootstrap <- function(dataset){
# für h=1
garch_fit_h1 <- ugarchfit (data = ts(dataset$ret1), spec = garch_spec_h1)
if( !(garch_fit_h1@fit$convergence == 0)){
return(NA)
}
forecasts_1 <-numeric(5)
for(i in tau){
bootpred = ugarchboot(garch_fit_h1, method = "Partial", n.ahead = 1, n.bootpred = 1000)
fseries <- apply(bootpred@fseries, 2, quantile, probs = i)
index <- match(i, tau)
forecasts_1[index] <- fseries[1]
}
# für h=2
garch_fit_h2 <- ugarchfit (data = ts(dataset$ret2), spec = garch_spec_h2)
if( !(garch_fit_h2@fit$convergence == 0)){
return(NA)
}
forecasts_2 <-numeric(5)
for(i in tau){
bootpred = ugarchboot(garch_fit_h2, method = "Partial", n.ahead = 2, n.bootpred = 1000)
fseries <- apply(bootpred@fseries, 2, quantile, probs = i)
index <- match(i, tau)
forecasts_2[index] <- fseries[2]
}
# für h=3
garch_fit_h3 <- ugarchfit (data = ts(dataset$ret3), spec = garch_spec_h3)
if( !(garch_fit_h3@fit$convergence == 0)){
return(NA)
}
forecasts_3 <-numeric(5)
for(i in tau){
bootpred = ugarchboot(garch_fit_h3, method = "Partial", n.ahead = 3, n.bootpred = 1000)
fseries <- apply(bootpred@fseries, 2, quantile, probs = i)
index <- match(i, tau)
forecasts_3[index] <- fseries[3]
}
# für h=4
garch_fit_h4 <- ugarchfit (data = ts(dataset$ret4), spec = garch_spec_h4)
if( !(garch_fit_h4@fit$convergence == 0)){
return(NA)
}
forecasts_4 <-numeric(5)
for(i in tau){
bootpred = ugarchboot(garch_fit_h4, method = "Partial", n.ahead = 4, n.bootpred = 1000)
fseries <- apply(bootpred@fseries, 2, quantile, probs = i)
index <- match(i, tau)
forecasts_4[index] <- fseries[4]
}
# für h=5
garch_fit_h5 <- ugarchfit (data = ts(dataset$ret5), spec = garch_spec_h5)
if( !(garch_fit_h5@fit$convergence == 0)){
return(NA)
}
forecasts_5 <-numeric(5)
for(i in tau){
bootpred = ugarchboot(garch_fit_h5, method = "Partial", n.ahead = 5, n.bootpred = 1000)
fseries <- apply(bootpred@fseries, 2, quantile, probs = i)
index <- match(i, tau)
forecasts_5[index] <- fseries[5]
}
predictions <- as.data.frame(rbind(forecasts_1, forecasts_2, forecasts_3, forecasts_4, forecasts_5))
colnames(predictions) = c("q0.025", "q0.25", "q0.5", "q0.75", "q0.975")
rownames(predictions) = c("ret1", "ret2", "ret3", "ret4", "ret5")
return(predictions)
}
garch_forecasts <- function(dataset){
# für h=1
garch_fit_h1 <- ugarchfit (data = ts(dataset$ret1), spec = garch_spec_h1)
if( !(garch_fit_h1@fit$convergence == 0)){
return(NA)
}
forc_1 <- ugarchforecast(fitORspec = garch_fit_h1, n.ahead = 1)
forecasts_1 <- qnorm(tau, mean = forc_1@forecast$seriesFor[1], sd = forc_1@forecast$sigmaFor[1])
# für h=2
garch_fit_h2 <- ugarchfit (data = ts(dataset$ret2), spec = garch_spec_h2)
if( !(garch_fit_h2@fit$convergence == 0)){
return(NA)
}
forc_2 <- ugarchforecast(fitORspec = garch_fit_h2, n.ahead = 2)
forecasts_2 <- qnorm(tau, mean = forc_2@forecast$seriesFor[2], sd = forc_2@forecast$sigmaFor[2])
# für h=3
garch_fit_h3 <- ugarchfit (data = ts(dataset$ret3), spec = garch_spec_h3)
if( !(garch_fit_h3@fit$convergence == 0)){
return(NA)
}
forc_3 <- ugarchforecast(fitORspec = garch_fit_h3, n.ahead = 3)
forecasts_3 <- qnorm(tau, mean = forc_3@forecast$seriesFor[3], sd = forc_3@forecast$sigmaFor[3])
# für h=4
garch_fit_h4 <- ugarchfit (data = ts(dataset$ret4), spec = garch_spec_h4)
if( !(garch_fit_h4@fit$convergence == 0)){
return(NA)
}
forc_4 <- ugarchforecast(fitORspec = garch_fit_h4, n.ahead = 4)
forecasts_4 <- qnorm(tau, mean = forc_4@forecast$seriesFor[4], sd = forc_4@forecast$sigmaFor[4])
# für h=5
garch_fit_h5 <- ugarchfit (data = ts(dataset$ret5), spec = garch_spec_h5)
if( !(garch_fit_h5@fit$convergence == 0)){
return(NA)
}
forc_5 <- ugarchforecast(fitORspec = garch_fit_h5, n.ahead = 5)
forecasts_5 <- qnorm(tau, mean = forc_5@forecast$seriesFor[5], sd = forc_5@forecast$sigmaFor[5])
predictions <- as.data.frame(rbind(forecasts_1, forecasts_2, forecasts_3, forecasts_4, forecasts_5))
colnames(predictions) = c("q0.025", "q0.25", "q0.5", "q0.75", "q0.975")
rownames(predictions) = c("ret1", "ret2", "ret3", "ret4", "ret5")
garch_fit_h5 <- ugarchfit (data = ts(garch_train_data$ret5), spec = garch_spec_h5)
forc_5 <- ugarchforecast(fitORspec = garch_fit_h5, n.ahead = 5)
forecasts_5 <- qnorm(tau, mean = forc_5@forecast$seriesFor[5], sd = forc_5@forecast$sigmaFor[5])
print(forecasts_5)
return(predictions)
}
garch_evaluation_matrix <- garch_val_data
garch_evaluation_matrix$QS <- NA
forecasts_garch <- garch_forecasts(bind_rows(garch_train_data, garch_val_data[1:53,]))
for(i in 1: (nrow(garch_val_data) - 6)) {
print (paste0("Fortschritt: ", i/ nrow(garch_val_data))) # Fortschrittsanzeige
dataset <- bind_rows(garch_train_data, garch_val_data[1:i,])
dataset <- tail(dataset, 365)
forecasts_garch <- garch_forecasts(dataset)
print(forecasts_garch)
if(!any(is.na(forecasts_garch))){
qs_score <- evaluation(datum= dataset$Datum[nrow(dataset)], data=garch_val_data, forecasts=forecasts_garch)
print(qs_score)
garch_evaluation_matrix$QS[i] <- qs_score
}
}
print(mean(garch_evaluation_matrix$QS, na.rm = TRUE))
